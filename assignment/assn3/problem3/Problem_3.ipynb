{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b498912e",
   "metadata": {},
   "source": [
    "## Problem 3: Taking stock (15 points)\n",
    "\n",
    "A joint distribution of data has a natural graph associated with it. When the distribution is multivariate normal, this graph is encoded in the pattern of zeros and non-zeros in the inverse of the covariance matrix, also known as the \"precision matrix.\"\n",
    "\n",
    "In class we demonstrated the graphical lasso for estimating the graph on ETF data.\n",
    "In this problem you will construct two different \"portfolios\" of stocks,\n",
    "and run the graphical lasso to estimate a graph, commenting on your results.\n",
    "\n",
    "All of the code you might need for this is contained in the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd03a6e",
   "metadata": {},
   "source": [
    "## Downloading data\n",
    "\n",
    "As demonstrated in class, we will use R to download equity prices from Yahoo Finance (via the BatchGetSymbols package), then analyze in Python.\n",
    "Your job is to construct two \"portfolios\" of stocks, each of which has some kind of organization to it. For example, in one portfolio you might have 5 energy stocks, 5 tech stocks, 5 consumer staples stocks, and 5 ETF stocks. Each portfolio should have at least 20 stocks.\n",
    "\n",
    "The page https://en.wikipedia.org/wiki/List_of_S%26P_500_companies lists GICS sectors (also written to `sp500_meta.csv` by the R script below).\n",
    "\n",
    "### R → CSV workflow\n",
    "Use the provided R script (`problem3_yahoo.Rmd`) to fetch prices in batched, cached calls and write CSVs for Python analysis.\n",
    "\n",
    "**What the R script does**\n",
    "- Scrapes the current S&P 500 membership (symbol, company, sector).\n",
    "- Downloads **raw prices** (Adjusted Close by default) for any tickers (S&P 500 or an ETF list), at **daily/weekly/monthly** frequency.\n",
    "- Writes:\n",
    "  - `sp500_meta.csv` — symbol/company/sector.\n",
    "  - `weekly_stock.csv` — prices for your example ETF set (weekly, unadjusted close in this demo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db038d",
   "metadata": {},
   "source": [
    "### Analyzing  your portfolios\n",
    "\n",
    "Your task is to analyze each porfolio using the graphical lasso, and comment on your findings.\n",
    "Here are the types of questions you should address:\n",
    "\n",
    "* How did you choose the portolio? How did you choose the date range and frequency (daily, weekly, etc.)? Remember, each of the portfolios must contain at least 20 stocks, and be organized in some reasonable way.\n",
    "\n",
    "* Display the graph obtained with the graphical lasso, using networkx. How did you choose the regularization level? Does the structure of the graph make sense? Is it sensitive to the choice of regularization level? Is this the structure you expected to see when you designed the portfolio? Why or why not?\n",
    "\n",
    "* What are some of the conditional independence assumptions implied by the graph? Are some parts of the graph more densely connected than others? Why?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "869211d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_stock.csv: 262 rows × 33 tickers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECH</th>\n",
       "      <th>EIDO</th>\n",
       "      <th>EIRL</th>\n",
       "      <th>EIS</th>\n",
       "      <th>ENZL</th>\n",
       "      <th>EPHE</th>\n",
       "      <th>EPOL</th>\n",
       "      <th>EPU</th>\n",
       "      <th>ERUS</th>\n",
       "      <th>EWA</th>\n",
       "      <th>...</th>\n",
       "      <th>EWS</th>\n",
       "      <th>EWT</th>\n",
       "      <th>EWU</th>\n",
       "      <th>EWW</th>\n",
       "      <th>EWY</th>\n",
       "      <th>EWZ</th>\n",
       "      <th>EZA</th>\n",
       "      <th>FXI</th>\n",
       "      <th>THD</th>\n",
       "      <th>TUR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-20</th>\n",
       "      <td>43.380001</td>\n",
       "      <td>25.950001</td>\n",
       "      <td>40.209999</td>\n",
       "      <td>51.689999</td>\n",
       "      <td>41.439999</td>\n",
       "      <td>34.189999</td>\n",
       "      <td>22.090000</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>32.650002</td>\n",
       "      <td>22.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.620001</td>\n",
       "      <td>33.669998</td>\n",
       "      <td>32.470001</td>\n",
       "      <td>51.560001</td>\n",
       "      <td>62.470001</td>\n",
       "      <td>37.119999</td>\n",
       "      <td>60.369999</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>77.470001</td>\n",
       "      <td>36.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>43.560001</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>40.060001</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>42.220001</td>\n",
       "      <td>34.160000</td>\n",
       "      <td>21.580000</td>\n",
       "      <td>34.080002</td>\n",
       "      <td>32.119999</td>\n",
       "      <td>22.610001</td>\n",
       "      <td>...</td>\n",
       "      <td>22.809999</td>\n",
       "      <td>33.230000</td>\n",
       "      <td>32.549999</td>\n",
       "      <td>51.169998</td>\n",
       "      <td>61.869999</td>\n",
       "      <td>37.459999</td>\n",
       "      <td>55.189999</td>\n",
       "      <td>38.490002</td>\n",
       "      <td>77.989998</td>\n",
       "      <td>35.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-03</th>\n",
       "      <td>44.849998</td>\n",
       "      <td>26.240000</td>\n",
       "      <td>39.959999</td>\n",
       "      <td>51.470001</td>\n",
       "      <td>42.150002</td>\n",
       "      <td>35.860001</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>22.309999</td>\n",
       "      <td>...</td>\n",
       "      <td>22.650000</td>\n",
       "      <td>33.240002</td>\n",
       "      <td>32.299999</td>\n",
       "      <td>52.070000</td>\n",
       "      <td>60.349998</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>54.369999</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>78.129997</td>\n",
       "      <td>35.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-10</th>\n",
       "      <td>45.130001</td>\n",
       "      <td>26.010000</td>\n",
       "      <td>40.160000</td>\n",
       "      <td>50.849998</td>\n",
       "      <td>42.310001</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>21.540001</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>22.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.639999</td>\n",
       "      <td>33.180000</td>\n",
       "      <td>32.419998</td>\n",
       "      <td>51.189999</td>\n",
       "      <td>59.919998</td>\n",
       "      <td>36.090000</td>\n",
       "      <td>57.180000</td>\n",
       "      <td>38.259998</td>\n",
       "      <td>78.650002</td>\n",
       "      <td>36.369999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-17</th>\n",
       "      <td>44.369999</td>\n",
       "      <td>26.230000</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>50.900002</td>\n",
       "      <td>42.439999</td>\n",
       "      <td>35.810001</td>\n",
       "      <td>22.090000</td>\n",
       "      <td>33.630001</td>\n",
       "      <td>31.070000</td>\n",
       "      <td>22.330000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.559999</td>\n",
       "      <td>32.959999</td>\n",
       "      <td>32.369999</td>\n",
       "      <td>51.369999</td>\n",
       "      <td>60.959999</td>\n",
       "      <td>36.160000</td>\n",
       "      <td>57.720001</td>\n",
       "      <td>37.959999</td>\n",
       "      <td>78.110001</td>\n",
       "      <td>37.779999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ECH       EIDO       EIRL        EIS       ENZL       EPHE  \\\n",
       "Date                                                                           \n",
       "2017-03-20  43.380001  25.950001  40.209999  51.689999  41.439999  34.189999   \n",
       "2017-03-27  43.560001  25.790001  40.060001  51.250000  42.220001  34.160000   \n",
       "2017-04-03  44.849998  26.240000  39.959999  51.470001  42.150002  35.860001   \n",
       "2017-04-10  45.130001  26.010000  40.160000  50.849998  42.310001  36.000000   \n",
       "2017-04-17  44.369999  26.230000  40.810001  50.900002  42.439999  35.810001   \n",
       "\n",
       "                 EPOL        EPU       ERUS        EWA  ...        EWS  \\\n",
       "Date                                                    ...              \n",
       "2017-03-20  22.090000  33.840000  32.650002  22.170000  ...  22.620001   \n",
       "2017-03-27  21.580000  34.080002  32.119999  22.610001  ...  22.809999   \n",
       "2017-04-03  21.959999  34.389999  31.900000  22.309999  ...  22.650000   \n",
       "2017-04-10  21.540001  33.750000  30.879999  22.430000  ...  22.639999   \n",
       "2017-04-17  22.090000  33.630001  31.070000  22.330000  ...  22.559999   \n",
       "\n",
       "                  EWT        EWU        EWW        EWY        EWZ        EZA  \\\n",
       "Date                                                                           \n",
       "2017-03-20  33.669998  32.470001  51.560001  62.470001  37.119999  60.369999   \n",
       "2017-03-27  33.230000  32.549999  51.169998  61.869999  37.459999  55.189999   \n",
       "2017-04-03  33.240002  32.299999  52.070000  60.349998  37.000000  54.369999   \n",
       "2017-04-10  33.180000  32.419998  51.189999  59.919998  36.090000  57.180000   \n",
       "2017-04-17  32.959999  32.369999  51.369999  60.959999  36.160000  57.720001   \n",
       "\n",
       "                  FXI        THD        TUR  \n",
       "Date                                         \n",
       "2017-03-20  39.250000  77.470001  36.730000  \n",
       "2017-03-27  38.490002  77.989998  35.799999  \n",
       "2017-04-03  38.740002  78.129997  35.250000  \n",
       "2017-04-10  38.259998  78.650002  36.369999  \n",
       "2017-04-17  37.959999  78.110001  37.779999  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# (Optional) Python helper: load the CSVs produced by the R script\n",
    "import pandas as pd\n",
    "try:\n",
    "    # Load prices written by the R script\n",
    "    fname = \"weekly_stock.csv\" \n",
    "    df = pd.read_csv(fname)\n",
    "\n",
    "    # Normalize date column name (could be 'date' or 'Date')\n",
    "    date_col = \"date\" if \"date\" in df.columns else (\"Date\" if \"Date\" in df.columns else None)\n",
    "    if date_col is None:\n",
    "        raise ValueError(\"No 'date' or 'Date' column found in CSV.\")\n",
    "\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.set_index(date_col).sort_index()\n",
    "    df.index.name = \"Date\"\n",
    "\n",
    "    print(f\"{fname}: {df.shape[0]} rows × {df.shape[1]} tickers\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Run the R script first to create weekly_stock.csv in this folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sds631",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
